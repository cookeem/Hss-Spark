#hadoop相关配置
hadoop {
  #把配置文件保存到hdfs的对应路径
  host-uri = "hdfs://localhost:9000"
  root-path = "hss"
  config-path = "conf"
  lib-path = "lib"
}


#spark相关配置
spark {
  master = "spark://127.0.0.1:7077"
  app-name = "KafkaSinkElasticSearch"
  stream-interval = 15
}

#elasticsearch相关配置
elasticsearch {
  nodes = "localhost:9200,localhost:9201"
  cluster-name = "my_cluster_name"
  hosts = [
    {
      host = "localhost"
      port = 9300
    },
    {
      host = "localhost"
      port = 9301
    }
  ]
  index-name = "hss"
  type-name = "hss_record"
  number-of-shards = 2
  number-of-replicas = 1
}
#kafka相关配置
kafka {
  from-beginning = 1
  zookeeper-uri = "localhost:2181"
  brokers-list = "localhost:9092"
  kafka-records-topic = "hss-records-topic"
  consume-group = "spark-consume-group"
}